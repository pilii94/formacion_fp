{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con Tensorflow: Dataset Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta Guia usa tf.keras, un API de alto nivel para construir y entrenar modelos en Tensorflow. El dataset Fashion MNIST contiene más de 70000 imagenes en 10 categorias. Las imagenes muestran articulos individuales de ropa a una resolucion baja (28 por 28 pixeles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from plot_functions_mnist import *\n",
    "# TensorFlow y tf.keras\n",
    "import tensorflow as tf ##pip install tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Librerias de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60,000 imagenes son usadas para entrenar la red neuronal y 10,000 imagenes son usadas para evaluar si aprende la red a clasificar imagenes. Vamos a importar y cargar el set de datos de MNIST directamente de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al cargar el set de datos, devuelve cuatro objetos en NumPy:\n",
    "\n",
    "+ Los objetos train_images y train_labels son los objetos de training — el modelo de datos los usa para aprender.\n",
    "+ El modelo es probado contra los objetos test set, el test_images, y test_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Los labels son números enteros, que van del 0 al 9. Estos corresponden a la clase de ropa que la imagen representa. Cada imagen es mapeada a una unica etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_dict = {\n",
    "  'T-shirt/top': 0,\n",
    "  'Trouser': 1,\n",
    "  'Pullover': 2,\n",
    "    'Dress':3,\n",
    "    'Coat': 4,\n",
    "    'Sandal':5,\n",
    "    'Shirt':6,\n",
    "    'Sneaker':7,\n",
    "    'Bag':8, \n",
    "    'Ankle boot':9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos el formato del set de datos antes de entrenar el modelo. Lo siguiente muestra que hay 60,000 imágenes en el set de entrenamiento, con cada imagen representada por píxeles de 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##dimensiones del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#número de ejemplos en el entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#número de ejemplos en el conjunto de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El set de datos debe ser pre-procesado antes de entrenar la red. Si inspeccionamos la primera imagen en el set de entrenamiento, veremos que los valores de los pixeles estan entre 0 y 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos los valores de cada pixel de la imagen en un rango de 0 a 1 antes de alimentarlos al modelo de la red neuronal. Para hacerlo, dividimos los valores por 255. Es importante que el training set y el testing set se pre-procesen siempre de la misma forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que el set de datos está en el formato adecuado y podemos construir y entrenar la red, vamos a mostrar las primeras 25 imagenes de el training set y mostramos el nombre de cada clase debajo de cada imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1) ##vamos a mostrar las gráficas posicionadas en 5 filas y 5 columnas\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)#blanco y negro\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construir la red neuronal requiere configurar las capas del modelo y luego compilar el modelo.\n",
    "\n",
    "La mayoria de aprendizaje profundo consiste de unir capas sencillas. La mayoria de las capas como tf.keras.layers.Dense, tienen parametros que son aprendidos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera capa de esta red, tf.keras.layers.Flatten, transforma el formato de las imágenes de un arreglo bi-dimensional (de 28 por 28 pixeles) a un arreglo uni dimensional (de 28*28 pixeles = 784 pixeles). Es como si separamos cada capa de las filas de pixeles de una imagen y las alineamos todas. Esta capa no tiene parametros que aprender; solo reformatea el conjunto de datos.\n",
    "\n",
    "Después de que los píxeles están \"aplanados\", la secuencia consiste de dos capas tf.keras.layers.Dense. Estas están densamente conectadas, o completamente conectadas. La primera capa Dense tiene 128 nodos (o neuronas). La segunda (y última) capa es una capa de 10 nodos softmax que devuelve 10 probabilidades que suman a 1. Estas indican la probabilidad de que la actual imagen pertenezca a una de las 10 clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),##reformateo de la disposición de los pixeles\n",
    "    keras.layers.Dense(128, activation='relu'),## 128 neuronas completamente conectadas\n",
    "    keras.layers.Dense(10, activation='softmax')##devuelve una probabilidad para cada numero del 0 al 9\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que el modelo esté listo para entrenar , se necesitan algunas configuraciones más. Estas son agregadas durante la compilación del modelo:\n",
    "\n",
    "+ Loss function —Esto mide qué tan exacto es el modelo durante el entrenamiento. Queremos minimizar esta función para dirigir el modelo en la dirección adecuada.\n",
    "+ Optimizer — Esto es como el modelo se actualiza basado en el set de datos que ve y la función de pérdida.\n",
    "+ Metrics — Se usan para monitorear los pasos de entrenamiento y de pruebas. Este ejemplo usa el accuracy (exactitud) , que indica la fracción de la imagenes que son correctamente clasificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el modelo de red neuronal requiere de los siguientes pasos:\n",
    "\n",
    "+ Pasamos los datos de entrenamiento al modelo. En este ejemplo , el set de datos de entrenamiento está en los objetos train_images y train_labels.\n",
    "+ El modelo aprende a asociar imágenes y etiquetas.\n",
    "+ Le pedimos al modelo que haga predicciones sobre un set de datos que se encuentran en el objeto test_images. Verificamos que las predicciones sean iguales a las etiquetas del objeto test_labels.\n",
    "\n",
    "Para comenzar a entrenar, llamamos al método model.fit, es llamado así porque fit (ajusta) el modelo a el set de datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este modelo alcanza una exactitud de 0.90 (o 90%) sobre el set de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo entrenado, podemos usarlo para hacer predicciones sobre nuevas imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, el modelo ha predecido la etiqueta para cada imagen en el set de datos de test (prueba). Miremos la primera predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ua prediccion es un arreglo de 10 números. Estos representan el nivel de \"confianza\" del modelo sobre las imágenes de cada uno de los 10 articulos de moda/ropa. Podemos revisar cual tiene el nivel más alto de confianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces,el modelo tiene mayor confianza que esta imagen es un bota de tobillo \"ankle boot\" o lo que es lo mismo, class_names[9]. Examinando las etiquetas de test o de pruebas muestra que esta clasificaion es correcta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos esto para poder ver todo el set de la prediccion de las 10 clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a probar con el dataset MNIST (Para el Reto...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Os atrevéis a intentar repetir el proceso con otro dataset? Este es muy similar, pero con números escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[1])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
